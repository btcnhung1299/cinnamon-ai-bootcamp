{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno -3] Temporary\n",
      "[nltk_data]     failure in name resolution>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './cornell-movie-dialogs-corpus'\n",
    "\n",
    "with open('{}/movie_lines.txt'.format(data_folder), 'rb') as movie_lines_file:\n",
    "    lines_data = movie_lines_file.read().decode(encoding='utf-8', errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.</b> First, we split text by endline symbol (`\\n`) to get list of utterances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last line (\"\") is an empty string, so we remove it from list of utterances.\n",
      "Number of utterances: 304713\n"
     ]
    }
   ],
   "source": [
    "utterances = lines_data.split(sep='\\n')\n",
    "print('Last line (\"{}\") is an empty string, so we remove it from list of utterances.'.format(utterances.pop()))\n",
    "print('Number of utterances:', len(utterances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.</b> Observations on first 10 samples suggest the string ` +++$+++ ` acts as seperator between 5 components of an utterance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> First 10 samples:\n",
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
      "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
      "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
      "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
      "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
      "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n",
      "L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
      "L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\n",
      "\n",
      "> Is there a line which does not have exactly 4 \"+++$+++\"?\n",
      "- False\n"
     ]
    }
   ],
   "source": [
    "print('> First 10 samples:')\n",
    "print(*utterances[:10], sep='\\n')\n",
    "\n",
    "print()\n",
    "\n",
    "print('> Is there a line which does not have exactly 4 \"+++$+++\"?')\n",
    "print('- {}'.format(any([line.count(' +++$+++ ') != 4 for line in utterances])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3.</b> We then split each utterance by the seperator and convert the whole list to dataframe. Each column in dataframe is renamed regarding its meanings provided in `README.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_data = pd.DataFrame([line.split(' +++$+++ ') for line in utterances],\n",
    "                               columns=['lineID', 'characterID', 'movieID', 'chacterter_name', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 9035\n",
      "Number of movies: 617\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lineID</th>\n",
       "      <th>characterID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>chacterter_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105836</th>\n",
       "      <td>L569571</td>\n",
       "      <td>u3129</td>\n",
       "      <td>m205</td>\n",
       "      <td>BETSY</td>\n",
       "      <td>All right.  All right. I'm taking a break at f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288463</th>\n",
       "      <td>L622567</td>\n",
       "      <td>u8570</td>\n",
       "      <td>m581</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>Drugs begin pouring out of America into every ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261712</th>\n",
       "      <td>L523606</td>\n",
       "      <td>u7741</td>\n",
       "      <td>m524</td>\n",
       "      <td>EARL</td>\n",
       "      <td>I don't look like no possum!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241586</th>\n",
       "      <td>L452534</td>\n",
       "      <td>u7158</td>\n",
       "      <td>m481</td>\n",
       "      <td>BIALYSTOCK</td>\n",
       "      <td>Okay, take it off, take it off.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174200</th>\n",
       "      <td>L184673</td>\n",
       "      <td>u5062</td>\n",
       "      <td>m334</td>\n",
       "      <td>THE PATIENT</td>\n",
       "      <td>I see.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lineID characterID movieID chacterter_name  \\\n",
       "105836  L569571       u3129    m205           BETSY   \n",
       "288463  L622567       u8570    m581          ROBERT   \n",
       "261712  L523606       u7741    m524            EARL   \n",
       "241586  L452534       u7158    m481      BIALYSTOCK   \n",
       "174200  L184673       u5062    m334     THE PATIENT   \n",
       "\n",
       "                                                     text  \n",
       "105836  All right.  All right. I'm taking a break at f...  \n",
       "288463  Drugs begin pouring out of America into every ...  \n",
       "261712                       I don't look like no possum!  \n",
       "241586                    Okay, take it off, take it off.  \n",
       "174200                                             I see.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of characters:', utterances_data['characterID'].nunique())\n",
    "print('Number of movies:', utterances_data['movieID'].nunique())\n",
    "print()\n",
    "utterances_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.</b> We define normal characters consisting of alphabetic letters and basic sentence punctuations. Others are considered as special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 35 special characters:\n",
      "\t, 6, `, |, \", 7, ;, -, %, 5, <, 3, +, &, 1, ], $, >, :, _, }, 2, =, /, *, 0, ), 9, 8, #, ~, {, 4, ^, [\n"
     ]
    }
   ],
   "source": [
    "characters = set()\n",
    "utterances_data['text'].apply(lambda text : characters.update(list(text)));\n",
    "\n",
    "# Set of special characters is the intersection\n",
    "# between set of letters appeared in the dataset and alphabet\n",
    "special_characters = characters.difference(string.ascii_letters + '.,!? \\'')    \n",
    "\n",
    "print('List of {} special characters:'.format(len(special_characters)))\n",
    "print(*special_characters, sep=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.</b> Remove special characters from text of utterances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lineID</th>\n",
       "      <th>characterID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>chacterter_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133350</th>\n",
       "      <td>L65567</td>\n",
       "      <td>u3865</td>\n",
       "      <td>m256</td>\n",
       "      <td>BARTON</td>\n",
       "      <td>Well, my pleasure. I could use a little lift m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112808</th>\n",
       "      <td>L619257</td>\n",
       "      <td>u3321</td>\n",
       "      <td>m220</td>\n",
       "      <td>MAVERICK</td>\n",
       "      <td>I'm fine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202350</th>\n",
       "      <td>L294088</td>\n",
       "      <td>u5962</td>\n",
       "      <td>m395</td>\n",
       "      <td>BUZZ</td>\n",
       "      <td>I like to think so! It's this little idea I be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70993</th>\n",
       "      <td>L389998</td>\n",
       "      <td>u2109</td>\n",
       "      <td>m136</td>\n",
       "      <td>MASSERIA</td>\n",
       "      <td>The kid just called me stupid.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244968</th>\n",
       "      <td>L470209</td>\n",
       "      <td>u7268</td>\n",
       "      <td>m491</td>\n",
       "      <td>CLEANER</td>\n",
       "      <td>This a con?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lineID characterID movieID chacterter_name  \\\n",
       "133350   L65567       u3865    m256          BARTON   \n",
       "112808  L619257       u3321    m220        MAVERICK   \n",
       "202350  L294088       u5962    m395            BUZZ   \n",
       "70993   L389998       u2109    m136        MASSERIA   \n",
       "244968  L470209       u7268    m491         CLEANER   \n",
       "\n",
       "                                                     text  \n",
       "133350  Well, my pleasure. I could use a little lift m...  \n",
       "112808                                          I'm fine.  \n",
       "202350  I like to think so! It's this little idea I be...  \n",
       "70993                      The kid just called me stupid.  \n",
       "244968                                        This a con?  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_special_characters = lambda text : ''.join([c for c in text if c not in special_characters])\n",
    "utterances_data['text'] = utterances_data['text'].apply(remove_special_characters)\n",
    "utterances_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3.</b> Lower casing, lemmatization and repeat removing are utilized to normalize utterance tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'argh'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Create a simple repeat replacer using regex\n",
    "class RepeatReplacer():\n",
    "    def __init__(self):\n",
    "        self.pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "        self.repl = r'\\1\\2\\3'\n",
    "    \n",
    "    def replace(self, word):\n",
    "        if wordnet.synsets(word):\n",
    "            return word\n",
    "        repl_word = self.pattern.sub(self.repl, word)\n",
    "        \n",
    "        # Recursively replace until it can't be replaced anymore\n",
    "        return repl_word if repl_word == word else self.replace(repl_word)\n",
    "\n",
    "RepeatReplacer().replace('aaaaaaaaaaaaaaarghhhh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text: What do you want from me?\n",
      "After tokenized: what do you want from me\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "\n",
    "replacer = RepeatReplacer()\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "preprocess = lambda text : ' '.join([lemmatizer.lemmatize(stemmer.stem(replacer.replace(\n",
    "                                    word.lower().strip(string.punctuation))))\n",
    "                                    for word in text.split()])\n",
    "\n",
    "sample_text = utterances_data['text'].sample().values[0]\n",
    "print('Sample text:', sample_text)\n",
    "print('After tokenized:', preprocess(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lineID</th>\n",
       "      <th>characterID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>chacterter_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44749</th>\n",
       "      <td>L282310</td>\n",
       "      <td>u1327</td>\n",
       "      <td>m89</td>\n",
       "      <td>CONOR</td>\n",
       "      <td>you'r no match for scot mr romirez we'r rais a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104584</th>\n",
       "      <td>L593013</td>\n",
       "      <td>u3111</td>\n",
       "      <td>m203</td>\n",
       "      <td>SOLLOZZO</td>\n",
       "      <td>i need two million dollar in cash...mor import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272064</th>\n",
       "      <td>L560627</td>\n",
       "      <td>u8025</td>\n",
       "      <td>m544</td>\n",
       "      <td>ALBERT</td>\n",
       "      <td>he thirtyf year old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155846</th>\n",
       "      <td>L133909</td>\n",
       "      <td>u4504</td>\n",
       "      <td>m298</td>\n",
       "      <td>EMILY</td>\n",
       "      <td>charl your your break this man neck would scar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>L3044</td>\n",
       "      <td>u41</td>\n",
       "      <td>m2</td>\n",
       "      <td>NICOLETTE</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lineID characterID movieID chacterter_name  \\\n",
       "44749   L282310       u1327     m89           CONOR   \n",
       "104584  L593013       u3111    m203        SOLLOZZO   \n",
       "272064  L560627       u8025    m544          ALBERT   \n",
       "155846  L133909       u4504    m298           EMILY   \n",
       "1286      L3044         u41      m2       NICOLETTE   \n",
       "\n",
       "                                                     text  \n",
       "44749   you'r no match for scot mr romirez we'r rais a...  \n",
       "104584  i need two million dollar in cash...mor import...  \n",
       "272064                                he thirtyf year old  \n",
       "155846  charl your your break this man neck would scar...  \n",
       "1286                                                 okay  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_data['text'] = utterances_data['text'].apply(preprocess)\n",
    "utterances_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct words: 47131\n"
     ]
    }
   ],
   "source": [
    "words = set()\n",
    "utterances_data['text'].str.split().apply(words.update)\n",
    "print('Number of distinct words:', len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "bag = count_vectorizer.fit_transform(utterances_data['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304713, 41554)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
